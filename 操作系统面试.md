、

## CPU如何写数据

- **CPU Line** 是 CPU 从内存读取数据到 Cache的单位
- 多个线程同时读写一个Cache Line的不同变量时，导致CPU Cache失效的现象叫做**伪共享**
  - 解决方法：在多核系统中，使用Cache line对齐



## CPU如何选择线程

- 在 Linux 内核中，进程和线程都是⽤  **tark_struct** 结构体表示的，区别在于线程的 tark_struct 结构体⾥部分资源是共享了进程已创建的资源，⽐如内存地址空间、代码段、⽂件描述符等，所以 Linux 中的线程也被称为轻量级进程，因为线程的 tark_struct 相⽐进程的 tark_struct 承载的 资源⽐较少，因此以「轻」得名。
- 完全公平调度（Completely Fair Scheduling）
  - 让分配给每个任务的 CPU 时间是⼀样，于是它为每个任务安排⼀个**虚拟运⾏时间 vruntime**，如果⼀个任务在运⾏，其运⾏的越久，该任务的 vruntime ⾃然就会越⼤，⽽没有被运⾏的任务，vruntime 是不会变化的。
  - 在 CFS 算法调度的时候，**会优先选择 vruntime 少的任务**，以保证每个任务的公平性



## 软中断

### 中断

- 中断是系统⽤来响应硬件设备请求的⼀种机制，操作系统收到硬件的中断请求，会打断正在执⾏的进程，然后调⽤内核中的中断处理程序来响应请求。
- 中断是⼀种异步的事件处理机制，可以提⾼系统的并发处理能⼒
- **中断请求的响应程序，也就是中断处理程序，要尽可能快的执⾏完，这样可以减少对正常进程运⾏调度地影响。**
- 中断处理程序在响应中断时，可能还会「临时关闭中断」，这意味着，如果当前中断处理程序没有执⾏完之前，系统中其他的中断请求都⽆法被响应，也就说中断有可能会丢失，所以中断处理程序要短且快。



### 软中断

- Linux 系统为了解决中断处理程序执⾏过⻓和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」
  - 上半部⽤来快速处理中断，⼀般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情。
  - 下半部⽤来延迟处理上半部未完成的⼯作，⼀般以**「内核线程」**的⽅式运⾏
- **上半部直接处理硬件请求，也就是硬中断**，主要是负责耗时短的⼯作，特点是快速执⾏；
- **下半部是由内核触发，也就说软中断**，主要是负责上半部未完成的⼯作，通常都是耗时⽐较⻓的事情，特点是延迟执⾏；



# 操作系统结构

## 内核

- 内核作为应⽤连接硬件设备的桥梁

<img src="C:\Users\ln\OneDrive\校招准备\操作系统\Pic\image-20210520163205706.png" alt="image-20210520163205706" style="zoom:33%;" />

- 内核的基本功能
  - **管理进程、线程**，决定哪个进程、线程使⽤ CPU，也就是**进程调度的能⼒**
  - **管理内存**，决定内存的分配和回收，也就是**内存管理的能⼒**
  - **管理硬件设备**，为进程与硬件设备之间提供通信能⼒，也就是**硬件通信能⼒**
  - **提供系统调⽤**，如果应⽤程序要运⾏更⾼权限运⾏的服务，那么就需要有系统调⽤，它是⽤户程序与操作系统之间的接⼝
- 内存分成了两个区域：
  - 内核空间，这个内存空间只有内核程序可以访问；
  - ⽤户空间，这个内存空间专⻔给应⽤程序使⽤；



# 内存管理

## 虚拟内存

- 进程持有的**虚拟地址**会通过 CPU 芯⽚中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存

<img src="C:\Users\ln\OneDrive\校招准备\操作系统\Pic\image-20210520204657042-1621514818405.png" alt="image-20210520204657042" style="zoom: 50%;" />

## 内存分段

- 程序是由若⼲个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。**不同的段是有不同的属性的，所以就⽤分段（Segmentation）的形式把这些段分离出来**
- 分段机制下的虚拟地址由两部分组成，**段选择⼦和段内偏移量**

<img src="C:\Users\ln\OneDrive\校招准备\操作系统\Pic\image-20210520205006065-1621515007399.png" alt="image-20210520205006065" style="zoom:67%;" />

- **段选择⼦**就保存在段寄存器⾥⾯。段选择⼦⾥⾯最重要的是**段号**，**⽤作段表的索引**。段表⾥⾯保存的是这个段的基地址、段的界限和特权等级等。
- 虚拟地址中的**段内偏移量**应该位于 **0 和段界限**之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。

- 缺点：
  - 内存碎⽚
    - **外部内存碎⽚**，也就是产⽣了多个不连续的⼩物理内存，导致新的程序⽆法被装载；
      - 解决方法：内存交换，在 Linux 系统⾥，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，⽤于**内存与硬盘的空间交换**
    - **内部内存碎⽚**，程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使⽤，这也会导致内存的浪费；
  - 内存交换的效率低
    - 如果内存交换（与硬盘经行交换）的时候，交换的是⼀个占内存空间很⼤的程序，这样整个机器都会显得卡顿

- 分段的好处就是能**产⽣连续的内存空间**，但是会出现**内存碎⽚和内存交换的空间太⼤的问题**。

## 内存分页

- 分⻚是把整个**虚拟和物理内存空间**切成⼀段段固定尺⼨的⼤⼩。这样⼀个连续并且尺⼨固定的内存空间叫作⻚（Page），在 Linux 下每⼀⻚的⼤⼩为  4KB 。

  <img src="C:\Users\ln\OneDrive\校招准备\操作系统\Pic\image-20210520210653525-1621516015323.png" alt="image-20210520210653525" style="zoom:67%;" />

- 当进程访问的虚拟地址在⻚表中查不到时，系统会产⽣⼀个缺⻚异常，进⼊系统内核空间分配物理内存、更新进程⻚表，最后再返回⽤户空间，恢复进程的运⾏

- 采⽤了分⻚，那么释放的内存都是以⻚为单位释放的，也就不会产⽣⽆法给进程使⽤的⼩内存

- 只有在程序运⾏中，**需要⽤到对应虚拟内存⻚⾥⾯的指令和数据时，再加载到物理内存⾥⾯去**

- 在分⻚机制下，虚拟地址分为两部分，**⻚号和⻚内偏移**。**⻚号作为⻚表的索引，⻚表包含物理⻚每⻚所在物理内存的基地址**，**这个基地址与⻚内偏移的组合就形成了物理内存地址**

  <img src="C:\Users\ln\OneDrive\校招准备\操作系统\Pic\image-20210520210758426.png" alt="image-20210520210758426" style="zoom:67%;" />

- 简单的分页会导致页表过大

### 多级⻚表

- 如果某个⼀级⻚表的⻚表项没有被⽤到，也就不需要创建这个⻚表项对应的⼆级⻚表了，即**可以在需要时才创建⼆级⻚表**
- 64位系统需要四级页表



### TLB

- 多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换需要消费更多的时间，带来了时间上的开销
- 把最常访问的⼏个⻚表项存储到访问速度更快的硬件
- 在 CPU 芯⽚中，加⼊了⼀个专⻔存放程序最常访问的⻚表项的 Cache，这个 Cache 就是 TLB（Translation Lookaside Buffer） ，通常称为⻚表缓存、转址旁路缓存、快表等
- 有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的⻚表。



##  段页式内存管理

- 将内存分段和内存分页组合起来
- 段⻚式内存管理实现的⽅式：
  - 先将程序划分为多个有逻辑意义的段，也就是前⾯提到的分段机制；
  - 接着再把每个段划分为多个⻚，也就是对分段划分出来的连续空间，再划分固定⼤⼩的⻚；
- 地址结构就由段号、段内⻚号和⻚内位移三部分组成。
- ⽤于段⻚式地址变换的数据结构是每⼀个程序⼀张段表，每个段⼜建⽴⼀张⻚表，段表中的地址是⻚表的起始地址，⽽⻚表中的地址则为某⻚的物理⻚号，如图所示
- <img src="C:\Users\ln\OneDrive\校招准备\操作系统\Pic\image-20210521104714458-1621565235736.png" alt="image-20210521104714458" style="zoom:67%;" />

- 虽然增加了硬件成本和系统开销，但提⾼了内存的利⽤率。



## Linux内存管理

- Linux 内存主要采⽤的是**⻚式内存管理**，但同时也不可避免地涉及了**段机制**。



# 进程与线程

## 进程

- 并发和并行
  - 并发：一个CPU执行多个任务
  - 并行：多个CPU同时执行多个任务

### 进程的状态

- 在⼀个进程的活动期间⾄少具备三种基本状态，即**运⾏状态、就绪状态、阻塞状态**。
  - **运⾏状态（Runing）**：该时刻进程占⽤ CPU；
  - **就绪状态（Ready）**：可运⾏，由于其他进程处于运⾏状态⽽暂时停⽌运⾏；
  - **阻塞状态（Blocked）**：该进程正在等待某⼀事件发⽣（如等待输⼊/输出操作的完成）⽽暂时停⽌运⾏，这时即使给它CPU控制权，它也⽆法运⾏；
- 另外两个状态
  - **创建状态（New）**：进程正在被创建时的状态；
  - **结束状态（Exit）**：进程正在从系统中消失时的状态；

<img src="C:\Users\ln\OneDrive\校招准备\操作系统\Pic\image-20210524210340579-1621861422303.png" alt="image-20210524210340579" style="zoom:67%;" />

- 在虚拟内存管理的操作系统中，通常会把**阻塞状态的进程**的物理内存空间换出到硬盘，等需要再次运⾏的时候，再从硬盘换⼊到物理内存。

- 挂起状态：描述进程没有占⽤实际的物理内存空间的情况

  - **阻塞挂起状态**：进程在外存（硬盘）并等待某个事件的出现
  - **就绪挂起状态**：进程在外存（硬盘），但只要进⼊内存，即刻⽴刻运⾏

  <img src="C:\Users\ln\OneDrive\校招准备\操作系统\Pic\image-20210525102437208-1621909480593.png" alt="image-20210525102437208" style="zoom:67%;" />

### 进程的控制结构

- 进程控制结构（PCB，process control block）
- **PCB 是进程存在的唯⼀标识**，这意味着⼀个进程的存在，必然会有⼀个 PCB，如果进程消失了，那么 PCB 也会随之消失。
- PCB包含的信息
  - 进程描述信息：
    - 进程标识符：标识各个进程，每个进程都有⼀个并且唯⼀的标识符；
    - ⽤户标识符：进程归属的⽤户，⽤户标识符主要为共享和保护服务；
  - 进程控制和管理信息：
    - 进程当前状态，如 new、ready、running、waiting 或 blocked 等；
    - 进程优先级：进程抢占 CPU 时的优先级；
  - 资源分配清单：
    - 有关内存地址空间或虚拟地址空间的信息，所打开⽂件的列表和所使⽤的 I/O 设备信息。
  - CPU 相关信息：
    - CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执⾏时，能从断点处继续执⾏。
- PCB通过**链表**进行组织
  - **把具有相同状态的进程链在⼀起，组成各种队列**
    - 将所有处于就绪状态的进程链在⼀起，称为**就绪队列**；
    - 把所有因等待某事件⽽处于等待状态的进程链在⼀起就组成各种**阻塞队列**
    - 另外，对于运⾏队列在单核 CPU 系统中则只有⼀个运⾏指针了，因为单核 CPU 在某个时间，只能运⾏⼀个程序。



### 进程的控制

#### 创建进程

- 操作系统允许⼀个进程创建另⼀个进程，⽽且允许⼦进程继承⽗进程所拥有的资源，当⼦进程被终⽌时，其在⽗进程处继承的资源应当还给⽗进程。同时，终⽌⽗进程时同时也会终⽌其所有的⼦进程。

- 创建过程
  - 为新进程分配⼀个唯⼀的进程标识号，并申请⼀个空⽩的 PCB，PCB 是有限的，若申请失败则创建失败；
  - 为进程分配资源，此处如果资源不⾜，进程就会进⼊等待状态，以等待资源；
  - 初始化 PCB；
  - 如果进程的调度队列能够接纳新进程，那就将进程插⼊到就绪队列，等待被调度运⾏；

#### 终止进程

- 进程可以有 3 种终⽌⽅式：**正常结束、异常结束以及外界⼲预（信号  kill 掉）**。
- 终止过程
  - 查找需要终⽌的进程的 PCB；
  - 如果处于执⾏状态，则⽴即终⽌该进程的执⾏，然后将 CPU 资源分配给其他进程；
  - 如果其还有⼦进程，则应将其所有⼦进程终⽌；
  - 将该进程所拥有的全部资源都归还给⽗进程或操作系统；
  - 将其从 PCB 所在队列中删除；

#### 阻塞进程

- 当进程需要等待某⼀事件完成时，它可以调⽤阻塞语句把⾃⼰阻塞等待。⽽⼀旦被阻塞等待，它只能由另⼀个进程唤醒。
- 阻塞过程
  - 找到将要被阻塞进程标识号对应的 PCB；
  - 如果该进程为运⾏状态，则保护其现场，将其状态转为阻塞状态，停⽌运⾏；
  - 将该 PCB 插⼊到阻塞队列中去；

#### 进程唤醒

- 进程由「运⾏」转变为「阻塞」状态是由于进程必须等待某⼀事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒⾃⼰的。
- 如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程⽤唤醒语句叫醒它。
- 唤醒过程
  - 在该事件的阻塞队列中找到相应进程的 PCB；
  - 将其从阻塞队列中移出，并置其状态为就绪状态；
  - 把该 PCB 插⼊到就绪队列中，等待调度程序调度；



### 进程的上下文切换

- ⼀个进程切换到另⼀个进程运⾏，称为**进程的上下⽂切换**
- CPU 上下⽂切换就是先把前⼀个任务的 CPU 上下⽂（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下⽂到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运⾏新任务
- 「任务」，主要包含**进程、线程和中断**。所以，可以根据任务的不同，把 CPU 上下⽂切换分成：**进程上下⽂切换、线程上下⽂切换和中断上下⽂切换**。
- 进程是由内核管理和调度的，所以**进程的切换只能发⽣在内核态**。
  - 进程的上下⽂切换不仅包含了虚拟内存、栈、全局变量等⽤户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。



## 线程

- 线程之间可以**并发运⾏**且**共享相同的地址空间**
- 线程是进程当中的⼀条执⾏流程
- 同⼀个进程内多个线程之间可以**共享代码段、数据段、打开的⽂件等资源**，但每个线程各⾃都有**⼀套独⽴的寄存器和栈**，这样可以确保线程的控制流是相对独⽴的。
- 线程的优缺点
  - 优点
    - ⼀个进程中可以同时存在多个线程；
    - 各个线程之间可以并发执⾏；
    - 各个线程之间可以共享地址空间和⽂件等资源；
  - 缺点
    - 当进程中的⼀个线程崩溃时，会导致其**所属进程的所有线程崩溃**。

#### 线程与进程的比较

- 比较/区别：
  - **进程是资源（包括内存、打开的⽂件等）分配的单位，线程是 CPU 调度的单位；**
  - 进程拥有⼀个完整的资源平台，⽽线程只独享必不可少的资源，如寄存器和栈；
  - 线程同样具有就绪、阻塞、执⾏三种基本状态，同样具有状态之间的转换关系；
  - 线程能减少并发执⾏的时间和空间开销；

- 线程相⽐进程能减少开销，体现在：
  - 线程的创建时间⽐进程快，因为进程在创建的过程中，还需要资源管理信息，⽐如内存管理信息、⽂件管理信息，⽽线程在创建的过程中，不会涉及这些资源管理信息，⽽是共享它们；
  - 线程的终⽌时间⽐进程快，因为线程释放的资源相⽐进程少很多；
  - 同⼀个进程内的线程切换⽐进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同⼀个进程的线程都具有同⼀个⻚表，那么在切换的时候不需要切换⻚表。⽽对于进程之间的切换，切换的时候要把⻚表给切换掉，⽽⻚表的切换过程开销是⽐较⼤的；
  - 由于同⼀进程的各线程间共享内存和⽂件资源，那么在线程之间数据传递的时候**，就不需要经过内核了**，这就使得线程之间的数据交互效率更⾼了；
- **不管是时间效率，还是空间效率线程⽐进程都要⾼**



#### 线程的上下文切换

- 线程与进程最⼤的区别在于：**线程是调度的基本单位，⽽进程则是资源拥有的基本单位。**
- 切换过程
  - 当两个线程不是属于同⼀个进程，则切换的过程就跟进程上下⽂切换⼀样；
  - **当两个线程是属于同⼀个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据；**
- 线程的上下⽂切换相⽐进程，开销要⼩很多



#### 线程的实现

- 三种实现方式
  - <font color='red'>**⽤户线程（User Thread）**</font>：在⽤户空间实现的线程，不是由内核管理的线程，是由⽤户态的线程库来完成线程的管理；
  - <font color='red'>**内核线程（Kernel Thread）**</font>：在内核中实现的线程，是由内核管理的线程；
  - <font color='red'>**轻量级进程（LightWeight Process）**</font>：在内核中来⽀持⽤户线程；
- 用户线程
  - ⽤户线程是基于⽤户态的线程管理库来实现的，那么线程控制块（Thread Control Block, TCB） 也是在库⾥⾯来实现的，对于操作系统⽽⾔是看不到这个 TCB 的，它只能看到整个进程的 PCB。
  - <font color='cornflowerblue'>**⽤户线程的整个线程管理和调度，操作系统是不直接参与的，⽽是由⽤户级线程库函数来完成线程的管理，包括线程的创建、终⽌、同步和调度等。**</font>
  - ⽤户线程的优点：
    - 每个进程都需要有它私有的线程控制块（TCB）列表，⽤来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由⽤户级线程库函数来维护，可⽤于不⽀持线程技术的操作系统；
    - <font color='orange'>⽤户线程的切换</font>也是由线程库函数来完成的，⽆需⽤户态与内核态的切换，所以<font color='orange'>速度特别快</font>；
  - ⽤户线程的缺点：
    - <font color='red'>由于操作系统不参与线程的调度，如果⼀个线程发起了系统调⽤⽽阻塞，那进程所包含的⽤户线程都不能执⾏了</font>。
    - 当⼀个线程开始运⾏后，除⾮它主动地交出 CPU 的使⽤权，否则它所在的进程当中的其他线程⽆法运⾏，因为⽤户态的线程没法打断当前运⾏中的线程，它没有这个特权，只有操作系统才有，但是⽤户线程不是由操作系统管理的。
    - 由于时间⽚分配给进程，故与其他进程⽐，在多线程执⾏时，每个线程得到的时间⽚较少，<font color='orange'>执⾏会⽐较慢</font>；
- 内核线程
  - <font color='red'>内核线程是由操作系统管理的，线程对应的 TCB ⾃然是放在操作系统⾥的，这样线程的创建、终⽌和管理都是由操作系统负责。</font>
  - 内核线程的优点：
    - 在⼀个进程当中，如果某个内核线程发起系统调⽤⽽被阻塞，并不会影响其他内核线程的运⾏；
    - 分配给线程，多线程的进程获得更多的 CPU 运⾏时间；
  - 内核线程的缺点：
    - 在⽀持内核线程的操作系统中，由内核来维护进程和线程的上下⽂信息，如 PCB 和 TCB；
    - 线程的创建、终⽌和切换都是通过系统调⽤的⽅式来进⾏，因此对于系统来说，系统开销⽐较⼤；
- 轻量级进程
  - <font color='red'>轻量级进程（Light-weight process，LWP）是内核⽀持的⽤户线程，⼀个进程可有⼀个或多个 LWP，每个 LWP 是跟内核线程⼀对⼀映射的，也就是 LWP 都是由⼀个内核线程⽀持</font>
  - LWP 只能由内核管理并像普通进程⼀样被调度，Linux 内核是⽀持 LWP 的典型例⼦



## 调度

- 选择⼀个进程运⾏这⼀功能是在操作系统中完成的，通常称为调度程序（scheduler）。

### 调度时机

- 在进程的⽣命周期中，当进程从<font color='cornflowerblue'>⼀个运⾏状态到另外⼀状态变化</font>的时候，其实会触发⼀次调度。
  - 从<font color='red'>就绪态 -> 运⾏态</font>：当进程被创建时，会进⼊到就绪队列，操作系统会从就绪队列选择⼀个进程运⾏；
  - 从<font color='red'>运⾏态 -> 阻塞态</font>：当进程发⽣ I/O 事件⽽阻塞时，操作系统必须另外⼀个进程运⾏；
  - 从<font color='red'>运⾏态 -> 结束态</font>：当进程退出结束后，操作系统得从就绪队列选择另外⼀个进程运⾏；
- 如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断，把调度算法分为两类：
  - <font color='red'>⾮抢占式调度算法</font>挑选⼀个进程，然后让该进程运⾏直到被阻塞，或者直到该进程退出，才会调⽤另外⼀个进程，也就是说不会理时钟中断这个事情。
  - <font color='red'>抢占式调度算法</font>挑选⼀个进程，然后让该进程只运⾏某段时间，如果在该时段结束时，该进程仍然在运⾏时，则会把它挂起，接着调度程序从就绪队列挑选另外⼀个进程。这种抢占式调度处理，需要在时间间隔的末端发⽣<font color='red'>时钟中断</font>，以便把 CPU 控制返回给调度程序进⾏调度，也就是常说的<font color='red'>时间⽚机制</font>。

### 调度原则

- <font color='red'>CPU 利⽤率</font>：调度程序应确保 CPU 是始终匆忙的状态，这可提⾼ CPU 的利⽤率；
- <font color='red'>系统吞吐量</font>：吞吐量表示的是单位时间内 CPU 完成进程的数量，⻓作业的进程会占⽤较⻓的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；
- <font color='red'>周转时间</font>：周转时间是进程运⾏和阻塞时间总和，⼀个进程的周转时间越⼩越好；
- <font color='red'>等待时间</font>：这个等待时间不是阻塞状态的时间，⽽是<font color='cornflowerblue'>进程处于就绪队列的时间</font>，等待的时间越⻓，⽤户越不满意；
- <font color='red'>响应时间</font>：⽤户提交请求到系统第⼀次产⽣响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。



### 调度算法

#### 单核CPU调度系统

- 先来先服务调度算法（First Come First Seved, FCFS）

  - ⾮抢占式：每次从就绪队列选择最先进⼊队列的进程，然后⼀直运⾏，直到进程退出或被阻塞，才会继续从队列中选择第⼀个进程接着运⾏。
  - FCFS **对⻓作业有利**，适⽤于 CPU 繁忙型作业的系统，⽽**不适⽤于 I/O 繁忙型作业的系统。**

- 最短作业优先调度算法（Shortest Job First, SJF）

  - <font color='red'>优先选择运⾏时间最短的进程来运⾏，这有助于提⾼系统的吞吐量。</font>
  - 这显然对⻓作业不利，很容易造成⼀种极端现象

- ⾼响应⽐优先调度算法（Highest Response Ratio Next, HRRN）

  - 每次进⾏进程调度时，先计算「响应⽐优先级」，然后把「响应⽐优先级」最⾼的进程投⼊运⾏，「响应⽐优先级」的计算公式：

    <img src="C:\Users\ln\OneDrive\校招准备\操作系统\Pic\image-20210525211343798-1621948425760.png" alt="image-20210525211343798" style="zoom: 50%;" />

  - 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应⽐」就越⾼，这样短作业的进程容易被选中运⾏；

  - 如果两个进程「要求的服务时间」相同时，「等待时间」越⻓，「响应⽐」就越⾼，这就兼顾到了⻓作业进程，因为进程的响应⽐可以随时间等待的增加⽽提⾼，当其等待时间⾜够⻓时，其响应⽐便可以升到很⾼，从⽽获得运⾏的机会；

- 时间⽚轮转调度算法（Round Robin, RR）

  - 最古⽼、最简单、最公平且使⽤最⼴的算法

    <img src="C:\Users\ln\OneDrive\校招准备\操作系统\Pic\image-20210525211718731.png" alt="image-20210525211718731" style="zoom:67%;" />

  - 每个进程被分配⼀个时间段，称为时间⽚（Quantum），即允许该进程在该时间段中运⾏。
    - 如果时间⽚⽤完，进程还在运⾏，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外⼀个进程；
    - 如果该进程在时间⽚结束前阻塞或结束，则 CPU ⽴即进⾏切换；
  - ⼀般来说，时间⽚设为 <font color='red'> 20ms~50ms </font>通常是⼀个⽐较合理的折中值。

- 最⾼优先级调度算法（Highest Priority First，HPF）

  - 进程的优先级可以分为，静态优先级和动态优先级：
    - 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运⾏时间优先级都不会变化；
    - 动态优先级：根据进程的动态变化调整优先级，⽐如如果进程运⾏时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升⾼其优先级，也就是随着时间的推移增加等待进程的优先级。
  - 也可分为抢占式和非抢占式

- 多级反馈队列调度算法（Multilevel Feedback Queue）

  - 多级反馈队列调度算法是「时间⽚轮转算法」和「最⾼优先级算法」的综合和发展。
    - 「多级」表示有多个队列，每个队列优先级从⾼到低，同时优先级越⾼时间⽚越短
    - 「反馈」表示如果有新的进程加⼊优先级⾼的队列时，⽴刻停⽌当前正在运⾏的进程，转⽽去运⾏优先级⾼的队列



## 进程间通信

### 管道

- 内核中的一段缓存，从一端写入另一端读取

- fork创建的⼦进程会复制⽗进程的⽂件描述符，这样就做到了两个进程各有两个「  fd[0] 与  fd[1] 」，两个进程就可以通过各⾃的 fd 写⼊和读取同⼀个管道⽂件实现跨进程通信了。

  <img src="C:\Users\ln\OneDrive\校招准备\操作系统\Pic\image-20210526110230232.png" alt="image-20210526110230232" style="zoom:67%;" />

- 管道只能一端写入，另一端读出，所以上面这种模式容易造成混乱，因为父进程和子进程都可以同时写入，也都可以读出。那么，为了避免这种情况，通常的做法是：
  - 父进程关闭读取的 fd[0]，只<font color='red'>保留写入的 fd[1]</font>；
  - 子进程关闭写入的 fd[1]，只<font color='red'>保留读取的 fd[0]</font>；
- 通信数据都遵循**先进先出**原则

### 消息队列

- 管道的通信方式是效率低的，不适合进程间频繁地交换数据
- **消息队列是保存在内核中的消息链表**
- 不足：
  - **一是通信不及时**
  - **二是大小有限制**
- **消息队列不适合比较大数据的传输**
- **<font color='cornflowerblue'>消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销</font>**

### 共享内存

- **<font color='cornflowerblue'>共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中</font>**。

<img src="C:\Users\ln\OneDrive\校招准备\操作系统\Pic\image-20210526111442410-1621998884605.png" alt="image-20210526111442410" style="zoom: 50%;" />

### 信号量

- 为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。正好，**<font color='red'>信号量</font>**就实现了这一保护机制
- **信号量其实是一个整型的计数器，主要用于<font color='blue'>实现进程间的互斥与同步</font>，而不是用于缓存进程间通信的数据**。
- 信号量表示资源的数量，控制信号量的方式有两种原子操作：
  - 一个是 **<font color='red'>P 操作</font>**，这个操作会把信号量减去 -1，相减后如果信号量 < 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使用，进程可正常继续执行。
  - 另一个是 **<font color='red'>V 操作</font>**，这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；
- P 操作是用在<font color='blue'>进入共享资源之前</font>，V 操作是用在<font color='blue'>离开共享资源之后</font>，这两个操作是必须成对出现的。
- 信号初始化为 `1`，就代表着是**互斥信号量**，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存。
- 信号初始化为 `0`，就代表着是**同步信号量**，它可以保证进程 A 应在进程 B 之前执行。

### 信号

- 信号是进程间通信机制中**<font color='blue'>唯一的异步通信机制</font>**，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式：
  - **执行默认操作**。
  - **捕捉信号**。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。
  - **忽略信号**。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SEGSTOP`，它们用于在任何时候中断或结束某一进程。

###  Socket

- **跨网络与不同主机上的进程之间通信，就需要 Socket 通信**



## 多线程同步

### 竞争与协作

- 多线程程序中线程是调度的基本单位，进程则是资源分配的基本单位

- 互斥概念

  - 竞争条件：当多线程相互竞争操作共享变量时，由于运气不好，即在执行过程中发生了上下文切换，我们得到了错误的结果，事实上，每次运行都可能得到不同的结果，因此输出的结果存在**不确定性（*indeterminate*）**

  - 临界区：多线程执行操作共享变量时可能会导致竞争状态的代码段，**它是访问共享资源的代码片段，一定不能给多线程同时执行。**

  - 互斥：**保证一个线程在临界区执行时，其他线程应该被阻止进入临界区**

    <img src="C:\Users\ln\OneDrive\校招准备\操作系统\Pic\image-20210526154750731.png" alt="image-20210526154750731" style="zoom:67%;" />

  - 互斥解决了<font color='red'>并发进程/线程</font>对临界区的使用问题

- 同步概念

  - 同步：**并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步**

### 互斥和同步的实现和使用

- 主要方式：
  - *锁*：加锁、解锁操作；
  - *信号量*：P、V 操作；

#### 锁

- 使用加锁操作和解锁操作可以解决并发线程/进程的**互斥问题**

- 任何想进入临界区的线程，必须先执行加锁操作。若加锁操作顺利通过，则线程可进入临界区；在完成对临界资源的访问后再执行解锁操作，以释放该临界资源。
- 根据锁的实现不同，可以分为<font color='blue'>「忙等待锁」</font>和<font color='blue'>「无忙等待锁」</font>
  - 忙等待锁
    - 当获取不到锁时，线程就会一直 wile 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为**自旋锁（*spin lock*）**
    - 在单处理器上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。
  - 无等待锁
    - 获取不到锁的时候，不用自旋
    - 那当没获取到锁的时候，就把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行

#### 信号量

- 信号量是操作系统提供的一种协调共享资源访问的方法
- 通常**信号量表示资源的数量**，对应的变量是一个整型（`sem`）变量
- **两个原子操作的系统调用函数来控制信号量的**
  - *P 操作*：将 `sem` 减 `1`，相减后，如果 `sem < 0`，则进程/线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞；
  - *V 操作*：将 `sem` 加 `1`，相加后，如果 `sem <= 0`，唤醒一个等待中的进程/线程，表明 V 操作不会阻塞；

- **信号量实现临界区的互斥访问**
  - 为每类共享资源设置一个信号量 `s`，<font color='red'>其初值为1</font>，表示该临界资源未被占用。
  - 对于两个并发线程，互斥信号量的值仅取 1、0 和 -1 三个值，分别表示：
    - 如果互斥信号量为 1，表示没有线程进入临界区；
    - 如果互斥信号量为 0，表示有一个线程进入临界区；
    - 如果互斥信号量为 -1，表示一个线程进入临界区，另一个线程等待进入。
  - 通过互斥信号量的方式，就能保证临界区任何时刻只有一个线程在执行，就达到了互斥的效果
- **信号量实现事件同步**
  - 同步的方式是设置一个信号量，<font color='red'>其初值为 0</font>



#### 生产者-消费者

![image-20210526164510233](C:\Users\ln\OneDrive\校招准备\操作系统\Pic\image-20210526164510233.png)

- 生产者-消费者问题描述：

  - **生产者**在生成数据后，放在一个缓冲区中；
  - **消费者**从缓冲区取出数据处理；
  - 任何时刻，**只能有一个**生产者或消费者可以访问缓冲区；

- 问题分析：

  - 任何时刻只能有一个线程操作缓冲区，说明操作缓冲区是临界代码，**需要互斥**；
  - 缓冲区空时，消费者必须等待生产者生成数据；缓冲区满时，生产者必须等待消费者取出数据。说明生产者和消费者**需要同步**。

- 三个信号量，分别是：

  - 互斥信号量 `mutex`：用于互斥访问缓冲区，初始化值为 1；
  - 资源信号量 `fullBuffers`：用于消费者询问缓冲区是否有数据，有数据则读取数据，初始化值为 0（表明缓冲区一开始为空）；
  - 资源信号量 `emptyBuffers`：用于生产者询问缓冲区是否有空位，有空位则生成数据，初始化值为 n （缓冲区大小）；

  <img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcJWrfgAR82HEMZFficYr34yX0HwhectDjLic12UOGxK1JDtBZSMwicZviaDboyeK8tuibboZuxHyQGLnQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 50%;" />

### 经典同步问题

#### 哲学家就餐

- 四个方案

#### 读者-写者问题

- 读者只会读取数据，不会修改数据，⽽写者即可以读也可以修改数据
- 读者-写者的问题描述：
  - 「读-读」允许：同一时刻，允许多个读者同时读
  - 「读-写」互斥：没有写者时读者才能读，没有读者时写者才能写
  - 「写-写」互斥：没有其他写者时，写者才能写



### 系统调用和函数调用的区别：

- 函数调用是调用函数库中的一个程序，而系统调用是调用系统内核的服务。
- 函数调用是与用户程序相联系，而系统调用是操作系统的一个进入点
- 函数调用是在用户地址空间执行，而系统调用是在内核地址空间执行
- 函数调用的运行时间属于「用户」时间，而系统调用的运行时间属于「系统」时间
- 函数调用属于过程调用，开销较小，而系统调用需要切换到内核上下文环境然后切换回来，开销较大
  

